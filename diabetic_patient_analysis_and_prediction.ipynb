{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetic Patient Analysis and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 20:15:54.875068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-03 20:16:04.465402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-03 20:16:04.465490: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-03 20:16:05.327796: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-03 20:16:32.247483: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-03 20:16:32.248407: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-03 20:16:32.248440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n",
      "Shape of feature variables : (691, 8)\n",
      "Shape of target variables : (691, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load the data file into Pandas DataFrame\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Explore the data loaded\n",
    "print(diabetes.dtypes)\n",
    "diabetes.head()\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "diabetes['Outcome'] = label_encoder.fit_transform(\n",
    "                        diabetes['Outcome'])\n",
    "\n",
    "# Convert Pandas DataFrame to a numpy vector\n",
    "np_diabetes = diabetes.to_numpy().astype(float)\n",
    "\n",
    "# Extract the feature variables (X)\n",
    "x = np_diabetes[:,1:9]\n",
    "x\n",
    "\n",
    "# Extract the target variable (Y), convert to one-hot-encoding\n",
    "y = np_diabetes[:,8]\n",
    "y = tf.keras.utils.to_categorical(y, 2)\n",
    "\n",
    "# Split training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10)\n",
    "\n",
    "print(\"Shape of feature variables :\", x_train.shape)\n",
    "print(\"Shape of target variables :\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 20:17:03.737250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-03 20:17:03.816100: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-03 20:17:03.816518: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Asl): /proc/driver/nvidia/version does not exist\n",
      "2022-12-03 20:17:04.150771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Dense-Layer-1 (Dense)       (None, 256)               2304      \n",
      "                                                                 \n",
      " Dense-Layer-2 (Dense)       (None, 256)               65792     \n",
      "                                                                 \n",
      " Dense-Layer-3 (Dense)       (None, 256)               65792     \n",
      "                                                                 \n",
      " Dense-Layer-4 (Dense)       (None, 256)               65792     \n",
      "                                                                 \n",
      " Final (Dense)               (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200,194\n",
      "Trainable params: 200,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 13s 271ms/step - loss: 5.4471 - accuracy: 0.5616 - val_loss: 8.2033 - val_accuracy: 0.3453\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 3.2221 - accuracy: 0.5217 - val_loss: 1.4313 - val_accuracy: 0.6331\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 96ms/step - loss: 1.1726 - accuracy: 0.5960 - val_loss: 0.9785 - val_accuracy: 0.5540\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.9505 - accuracy: 0.5417 - val_loss: 0.8251 - val_accuracy: 0.6547\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.9267 - accuracy: 0.5924 - val_loss: 0.8284 - val_accuracy: 0.5755\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.7494 - accuracy: 0.6322 - val_loss: 0.7119 - val_accuracy: 0.6403\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.7730 - accuracy: 0.6159 - val_loss: 0.6814 - val_accuracy: 0.6043\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.8039 - accuracy: 0.5833 - val_loss: 0.7480 - val_accuracy: 0.5755\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.6541 - accuracy: 0.6341 - val_loss: 0.7585 - val_accuracy: 0.6619\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.7295 - accuracy: 0.6214 - val_loss: 0.9275 - val_accuracy: 0.5971\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.8116 - accuracy: 0.6232 - val_loss: 0.5991 - val_accuracy: 0.6331\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6502 - accuracy: 0.6775 - val_loss: 0.6393 - val_accuracy: 0.6475\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.7597 - accuracy: 0.5870 - val_loss: 0.6710 - val_accuracy: 0.7122\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 1s 164ms/step - loss: 0.6242 - accuracy: 0.6612 - val_loss: 0.8419 - val_accuracy: 0.6403\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 92ms/step - loss: 0.7001 - accuracy: 0.6341 - val_loss: 0.6899 - val_accuracy: 0.5324\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.7644 - accuracy: 0.6178 - val_loss: 0.7674 - val_accuracy: 0.6331\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.7554 - accuracy: 0.5507 - val_loss: 0.6057 - val_accuracy: 0.7050\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.6053 - accuracy: 0.6685 - val_loss: 0.6070 - val_accuracy: 0.6619\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6154 - accuracy: 0.6612 - val_loss: 0.6681 - val_accuracy: 0.6619\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.6083 - accuracy: 0.6612 - val_loss: 0.6186 - val_accuracy: 0.6763\n",
      "\n",
      "Evaluation against Test Datase :\n",
      "--------------------------------------\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.5795 - accuracy: 0.6883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.579460859298706, 0.6883116960525513]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Setup Training Parameters\n",
    "EPOCHS=20\n",
    "BATCH_SIZE=128\n",
    "VERBOSE=1\n",
    "OUTPUT_CLASSES=len(label_encoder.classes_)\n",
    "N_HIDDEN=256\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "# Create a Keras sequential model\n",
    "diabetes_model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "# Add a Dense Layer\n",
    "diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                                input_shape=(8,),\n",
    "                                name='Dense-Layer-1',\n",
    "                                activation='relu'))\n",
    "\n",
    "# Add a second dense layer\n",
    "diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                                name='Dense-Layer-2',\n",
    "                                activation='relu'))\n",
    "\n",
    "# Add a third dense layer\n",
    "diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                                name='Dense-Layer-3',\n",
    "                                activation='relu'))\n",
    "\n",
    "# Add a fourth dense layer\n",
    "diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "                                name='Dense-Layer-4',\n",
    "                                activation='relu'))\n",
    "\n",
    "# # Add a fifth dense layer\n",
    "# diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "#                                 name='Dense-Layer-5',\n",
    "#                                 activation='relu'))\n",
    "\n",
    "# # Add a sixth dense layer\n",
    "# diabetes_model.add(keras.layers.Dense(N_HIDDEN,\n",
    "#                                 name='Dense-Layer-6',\n",
    "#                                 activation='relu'))\n",
    "\n",
    "# Add a softmax layer for categorical prediction\n",
    "diabetes_model.add(keras.layers.Dense(OUTPUT_CLASSES,\n",
    "                                name='Final',\n",
    "                                activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "diabetes_model.compile(\n",
    "                        loss='categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "diabetes_model.summary()\n",
    "\n",
    "# Build the model\n",
    "diabetes_model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=VERBOSE,\n",
    "                    validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "# Evaluate the model against the test datasetand print resullts\n",
    "print(\"\\nEvaluation against Test Datase :\\n--------------------------------------\")\n",
    "diabetes_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 342ms/step\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Pass individual patient to Predict either he/she have diabetese or not ?\n",
    "import numpy as np\n",
    "\n",
    "Pregnancies=10\n",
    "Glucose=101\n",
    "BloodPressure=76\n",
    "SkinThickness=48\n",
    "Insulin=180\n",
    "BMI=32.9\n",
    "DiabetesPedigreeFunction=0.171\n",
    "Age=63\n",
    "prediction=np.argmax(diabetes_model.predict([[Pregnancies,Glucose,BloodPressure,SkinThickness,Insulin,BMI,DiabetesPedigreeFunction,Age]]), axis=1)\n",
    "# print(label_encoder.inverse_transform(prediction)==True)\n",
    "print(label_encoder.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7280da05a75c96f949a2706eb9bb616f6fabc8d5a8f35c118d3936a4a8fc98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
